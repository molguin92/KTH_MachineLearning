\documentclass{kthreport}
% default language is English, but you can use Swedish definitions like this:
% \documentclass[swedish]{kthreport}

% Remember that in order for the class to find the KTH logo, you need to
% have it in your path, for example:
% export TEXINPUTS=/path/to/logo/location//:$TEXINPUTS

\usepackage[libertine,cmintegrals,cmbraces,vvarbb]{newtxmath}
\usepackage[backend=biber, sorting=none]{biblatex}
\addbibresource{bibl.bib}
\usepackage{listings}
\usepackage{xcolor}

\let\openbox\relax
\usepackage{amsthm}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\let\endopenbox\relax

\usepackage{amsmath}
\usepackage{csquotes}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{lightgray}{rgb}{0.95, 0.95, 0.95}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\lstdefinestyle{MyPython}{
	language=Python,
	frame=Lbtr,
	xleftmargin=\parindent,
	captionpos=b,
	aboveskip=3mm,
	belowskip=3mm,
	showstringspaces=false,
	columns=flexible,
	basicstyle={\small\ttfamily},
	numbers=left,
	numberstyle=\tiny\color{gray},
	keywordstyle=\color{purple},
	commentstyle=\color{gray},
	stringstyle=\color{dkgreen},
	breaklines=true,
	breakatwhitespace=true,
	tabsize=4,
	morekeywords={traci, print},
	otherkeywords={},
	backgroundcolor=\color{lightgray},
	escapeinside={/l*}{*l/}
}

\usepackage{url}

%\DeclareFontFamily{\encodingdefault}{\ttdefault}{\hyphenchar\font=`\-}

\title{Final Assignment}
\subtitle{DD3431 Machine Learning (PhD variant)}
\author{Manuel Osvaldo Olgu√≠n}
%\diarienr{99999-99}

\begin{document}
\maketitle

This final report for the DD3431 Machine Learning course describes the application of Linear Support Vector Machines to a multi-class, multi-output classification problem modeling the resource allocation strategies for basestations in a 5G environment. The classifier was adapted to the multi-class nature of the output.

\section{Theoretical description of the problem}

\subsection{Description of the data}\label{sec:data}

The data used for this study corresponds to samples of the resource allocation for a communication system composed of exactly three basestations and up to a maximum of 20 user devices. The area of interest studied within this communication scenario is modeled as a map; more specifically, it represents an area of 2400 m$^{2}$ divided into a grid of 2m$\times$2m cells. This grid is encoded as a matrix, with values between 0 and 2 indicating the occupancy status of each cell:
\begin{itemize}
	\item 0 for empty cells,
	\item 1 for cells occupied by a user device,
	\item 2 for cells occupied by a basestation.
\end{itemize}

The occupancy data for each user could be either perfect or have an inaccuracy defined by a normal distribution with three possible standard deviations: 0.1, 0.25 or 0.4. Thus, the model had to be trained a total of four times, one for each variation of the positioning inaccuracy (we'll call them ``scenarios''). 

The input data for the learning algorithm corresponds then to the vectorized form of this matrix, i.e. a vector of 600\footnote{$\frac{2400}{(2\times2)} = 600$} elements, each with a value $v_i \in \{0, 1, 2\}$.

On the other hand, the output data for the learning algorithm corresponds to encoded variables representing the basestation--user device association and the resource allocation information for each sample. The exact details of this encoding and the information carried within escape the scope of this report, but it is of importance to note that:
\begin{itemize}
	\item there are 9 of these output variables per input sample (3 for each basestation in the model);
	\item these output variables are mutually independent;
	\item they have discrete integer values that range between 0 and 12 288;
	\item these values can be repeated across variables;
	\item finally, the order in which these values appear in the output is relevant (i.e. permutations of the same values correspond to different output classes!).
\end{itemize} 

In summary, the structure of an arbitrary sample looks like the following:

\[\underbrace{0, 1, 0, 0, 2, 0, \ldots 0, 0, 0, 0, 0, 1,}_{\text{600 input features}}\underbrace{4567, 23, \ldots , 1337}_{\text{9 output labels}}\]

In total, 72 000 samples in this format for each scenario were provided for the training of the model, with two thirds (48 000) of these used for fitting and the rest (24 000) used for validation purposes. The complete dataset was also used for 10-fold cross-validation, again for each scenario.

\subsection{Adapting the data} \label{sec:problemtransform}

As described in the previous section, the data represents a multi-class, multi-label problem with a high dimensionality both in terms of input features and classes, with the additional restriction that the order of the output labels matters. \autocite{tsoumakas2009mining}

\subsection{Choice and adaptation of classifier}\label{sec:cfchoice}

The dataset in question is part of ongoing research at the Department of Information Science and Engineering of the School of Electrical Engineering, and has already been modeled with great success using Random Forests and Neural Networks. The application of Support Vector Machines was then a natural step given the models' popularity in networking research literature; the specific application of the Linear Kernel for SVMs was a result of experimentation with the dataset, where initial experiments exposed the linearly separatable nature of the output variables.

Support Vector Machines are binary classifiers though, and thus additional modifications are required to adapt these classifiers to multiclass problems as the one in question. Specifically, the following techniques for adapting binary classifiers to multiclass applications were identified from literature \autocite{hsu2002comparison,tax2002multiclass}:

\begin{itemize}
	\item One-vs-One Method: For $n$ classes, this method constructs $n(n-1)/2$ classifiers, each comparing a pair of classes from the training set. For prediction, all $n(n-1)/2$ classifiers are applied to an unseen sample, whose final class corresponds to the class with the most ``votes'' after processing. In case of a tie, it selects the class with the highest total confidence, obtained by aggregating the confidence scores of each binary classifier.
	\item One-vs-Rest Method: Constructs $n$ classifiers, each comparing one class in the training set with the rest (i.e. each classifier determines if a sample belongs to a specific class or not). At prediction time, these $n$ classifiers are applied to the unseen sample and it is once again classified according to the majority vote.
\end{itemize}

Other multiclass adaptations of binary classifiers, like DAGSVM \autocite{chen2009dagsvm} and DDAG \autocite{platt2000ddag} were considered as well, but were ultimately considered overly complex for the problem at hand and dismissed.



\section{Implementation}

\subsection{Language and libraries used}

The language chosen for this project was Python 3.6, given its extensive support for scientific programming, data analysis and machine learning in the form of libraries. In particular, the libraries \textbf{scikit-learn} (and its multilabel extension, \textbf{scikit-multilearn}), \textbf{scipy}, \textbf{matplotlib} and \textbf{numpy} were used for the implementation \autocite{scikit-learn,scikit-multilearn,scipy,matplotlib,numpy}.

\subsection{Choice of classifier}

Based on the analysis detailed in section \ref{sec:cfchoice}, \textbf{sklearn.svm.LinearSVC} was selected as the base classifier to be used for this problem, as it corresponds to an implementation of a multi-class Support Vector Machine using the \emph{One-vs-Rest} method and a linear kernel. Tests were also conducted with \textbf{sklearn.svm.SVC}, which implements a multi-class SVM using the \emph{One-vs-One} method and a RBF-kernel, but its runtime proved to be cumbersomely large\footnote{Not a fair comparison, but for the unoptimized SVC case the runtime was over 3 hours for fitting and predicting, whereas the final optimized runtime for the LinearSVC is, on average, 110 seconds.}.

The classifier was then extended to work on multilabel outputs through the \textbf{skmultilearn.problem\_transform.LabelPowerSet} class, which implements the \emph{Label Powerset} problem transformation as detailed in \ref{sec:problemtransform}, thus treating every distinct label combination in the training data as a separate class to pass to the multiclass classifier.

\subsection{Parsing and adapting the data}

The data provided for building the model consisted of 72 000 samples for each of the four positional accuracy values detailed in the problem description (section \ref{sec:data}), divided into two files each: two thirds (48 000) of the samples for training, and one third (24 000) for validation. The format of the input files was one sample per line: 600 integers with values in $\{0, 1, 2\}$ representing the input features, followed by 9 integers with values in $[0, 12288]$ representing the output variables (everything separated by commas, see example below).

\begin{lstlisting}[captionpos=b,
				basicstyle={\small\ttfamily},
				numbers=left, 
				numberstyle=\tiny\color{gray},
				caption={Abbreviated example of input samples.}]
0,0,0,...,0,2,0,...,3968,3841,528,8080,4209,6273,9201,9073,8592
0,0,0,...,0,2,0,...,80,2545,2417,6145,8176,4112,8443,11761,8736
0,0,0,...,0,2,0,...,3680,0,0,4112,8017,7408,10241,8272,11505
\end{lstlisting}

This data was parsed using \textbf{numpy}'s \textbf{loadfromtxt()} function, and then split into separate arrays for the input and output data (labels). The input data was passed ``as-is'' to the classifier, but the output data required additional processing which will be detailed below.


As mentioned before, the output labels for each case were presented in the form of 9 consecutive integers, each ranging in value from 0 to 12 288. On the other hand, as per the API specifications\footnote{\url{http://scikit.ml/api/datasets.html#the-multi-label-data-representation}} of \textbf{scikit-multilearn}, when using the \textbf{LabelPowerSet} problem transformation, the output labels passed to (and obtained from) the classifier need to be encoded into a \emph{binary indicator matrix}. 

\begin{definition}
	A binary indicator matrix for a set of $\eta$ samples, each with $\kappa$ associated output labels out of a universe $K$ of distinct possible labels, is a matrix $A$ of dimensions $(\eta \times |K|)$, where
	
	\[ A_{i,j} = \begin{cases}
	1 \text{ if label } j \in K \text{ is assigned to sample } i \\
	0 \text{ otherwise }
	\end{cases} \]
	
	Thus, $A$ is a sparse matrix where each row has \emph{at most} $\kappa$ elements of value $1$.
\end{definition}

Note that binary indicator matrices \emph{do not preserve information about label positions} in the output.
Consider two sets of labels $\alpha$ and $\beta$, where $\beta$ is a permutation of $\alpha$ -- i.e. both have the same labels but in different order. 
Given the previous definition of a the binary indicator matrix, both sets would then have the same representation in the matrix, since each element of a row only indicates if the label is present in the output. 
They also don't handle repeated labels correctly -- multiples of a label are all assigned to the same element of the matrix.

All of this poses a big problem for the model in question, where there can be repeated values in the output variables, and the order of which is relevant for the result. This meant that additional preprocessing of the data was necessary to encode the positional data of each output variable into the binary indicator matrix -- this would additionally solve the repetition problem, since variables with equal values but different positions would have different encodings.

In the end, the following function was applied to each label in the output:

\[ f(\nu, i) = (i * |K|) + \nu \]

Where $\nu$ is the value of the output variable (label), $i$ corresponds to the $0$-indexed position of the variable in the output vector and $K$ is the universe of valid labels ($K = [0, 12288]$ in this particular case). 
In practice, the result is that the first variable is assigned a value between $0$ and $|K| - 1$, the second variable a new value between $|K|$ and $2|K| - 1$, the third between $2|K|$ and $3|K| - 1$ and so on. 
This ensures that when encoding the output variables into a binary indicator matrix, variables retains the information about the position they occupied in the original vector -- and since the new values are all distinct (since they depend on the individual position of each variable and no two variables share the same position) it also solves the problem of duplicate variables ``disappearing'' in the binary indicator matrix.

Finally, to revert the previous transformation (for instance, when getting the results from the classifier), one only needs to apply the following:

\[ \nu' = f(\nu, i) \]
\[ \nu = \nu' \text{ mod } |K| \]
\[ i = \frac{\nu' - \nu}{|K|} \]

\subsection{Fitting and predicting}

The fitting and predicting was performed in parallel for the four accuracy 

\subsection{Validating}

\printbibliography

\end{document}
